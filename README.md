# ğŸ¥ MultiMedia AI

This project is a **Proof of Concept (POC)** showcasing multimodal AI orchestration.  
It generates an **image from text**, creates **narration audio**, and combines them into a **video** using open-source models and free tools.

---

## ğŸš€ Features
- **Text â†’ Image** using Stable Diffusion (Hugging Face Diffusers)
- **Text â†’ Audio** using gTTS (Google Text-to-Speech)
- **Combine** into video with MoviePy
- Lightweight (runs on CPU, no GPU required)

---

## ğŸ“‚ Project Structure
â”‚â”€â”€ main.py # Main script
â”‚â”€â”€ requirements.txt # Dependencies
â”‚â”€â”€ README.md # Project documentation
â”‚â”€â”€ poc_outputs/ # Generated outputs
â”‚ â”œâ”€â”€ generated_image.png
â”‚ â”œâ”€â”€ narration.wav
â”‚ â”œâ”€â”€ final_demo.mp4


---

## âš™ï¸ Installation & Setup (Windows)

### 1. Clone repository
```powershell
   git clone https://github.com/your-username/multimodal_poc_simple.git
   cd multimodalAI
```
### 2. Create virtual environment
py -3.10 -m venv venv
.\venv\Scripts\activate

### 3. Install requirements
pip install --upgrade pip
pip install -r requirements.txt
pip install imageio[ffmpeg] pydub

### 4. â–¶ï¸ Run the Program
python main.py

